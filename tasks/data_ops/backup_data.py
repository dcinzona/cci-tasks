
from pathlib import Path
import typing as T
# from tempfile import TemporaryDirectory

from cumulusci.core.datasets import Dataset, _make_task
from cumulusci.tasks.bulkdata.extract import ExtractData
from tasks.data_ops.generate_full_mapping import GenerateFullMapping
from cumulusci.tasks.sample_data.capture_sample_data import CaptureSampleData
from cumulusci.tasks.salesforce.BaseSalesforceApiTask import BaseSalesforceApiTask
from cumulusci.tasks.bulkdata.generate_mapping_utils.generate_mapping_from_declarations import (
    SimplifiedExtractDeclarationWithLookups,
    )
from cumulusci.salesforce_api.org_schema import Filters, get_org_schema
from cumulusci.salesforce_api.filterable_objects import OPT_IN_ONLY, NOT_COUNTABLE  # , NOT_EXTRACTABLE
from cumulusci.tasks.bulkdata.extract_dataset_utils.extract_yml import (
    ExtractRulesFile,
    ExtractDeclaration
)
from cumulusci.tasks.bulkdata.mapping_parser import validate_and_inject_mapping
from cumulusci.tasks.bulkdata.step import DataOperationType
from cumulusci.core.exceptions import TaskOptionsError
from cumulusci.salesforce_api.org_schema import Schema

from cumulusci.tasks.bulkdata.mapping_parser import MappingStep as CumulusciMappingStep
from cumulusci.tasks.bulkdata.mapping_parser import MappingSteps as CumulusciMappingSteps
from typing import Mapping, Dict

import copy

capture_options = copy.deepcopy(CaptureSampleData.task_options)
capture_options["extraction_definition"]["required"] = True
generate_full_mapping_options = copy.deepcopy(GenerateFullMapping.task_options)
extract_data_options = copy.deepcopy(ExtractData.task_options)
extract_data_options["mapping"]["required"] = False  # this will be generated by capture


class BackupData(BaseSalesforceApiTask):
    """
    Task to backup data from a Salesforce org to a local directory.
    Example: cci task run backup_data --dataset <folderName> --org <org_alias> --extraction-defition datasets/extract_accounts.yml
    """

    task_options = {
        "extraction_definition": {
            "description": "The path to the extraction definition file. File will be created if it does not exist",
            "required": False,
        },
        "dataset": {
            "description": "The name of the dataset to extract",
            "required": True,
        }
    }

    always_include_objects = ["User", "Group"]

    def _init_options(self, kwargs):
        super()._init_options(kwargs)
        if "preview" in self.options:
            self.preview = True
        else:
            self.preview = False
        if "dataset" in self.options:
            self.name = self.options['dataset']
        else:
            self.name = self.options['dataset'] = "default"

    def datasets_path(self) -> Path:
        return Path(self.project_config.repo_root or "") / "datasets" / self.name

    def extract_file(self) -> Path:
        return self.path / f"{self.name}.extract.yml"

    def _run_task(self):

        not_countable = NOT_COUNTABLE + ("NetworkUserHistoryRecent", "OutgoingEmail", "OutgoingEmailRelation")

        sobjectList = [f for f in self.sf.describe()["sobjects"] 
                       if f["queryable"] is True
                       and f["createable"] is True
                       and f["keyPrefix"] is not None
                       and f["associateEntityType"] is None
                       and f["name"] not in not_countable
                       ]
        extractable_data = [f["name"] for f in sobjectList]
        extractable_data = list(set(extractable_data + self.always_include_objects))
        opt_in_only = [f["name"] for f in self.tooling.describe()["sobjects"] if f["name"] not in extractable_data]  # type: ignore
        opt_in_only += OPT_IN_ONLY
        
        with get_org_schema(
            self.sf,
            self.org_config,
            include_counts=True,
            included_objects=extractable_data,
            filters=[Filters.queryable],
        ) as schema, Dataset(
            self.name,
            self.project_config,
            self.sf,
            self.org_config,
            schema,
        ) as dataset:

            if not dataset.path.exists():
                dataset.create()

            if extraction_definition := self.options.get("extraction_definition"):
                extraction_definition = Path(extraction_definition)
                if not extraction_definition.exists():
                    extraction_definition = dataset.extract_file
            else:
                extraction_definition = dataset.extract_file
            
            self.decls = ExtractRulesFile.parse_extract(extraction_definition)
            mappingDict = self.create_extract_mapping_file_from_declarations(
                list(self.decls.values()), schema, []
            )

            self.logger.info(f"Extracted Mapping: {mappingDict}")

            sobjectArray = list(mappingDict.keys())  # + self.always_include_objects
            sobjectListString = ",".join(list(set(sobjectArray)))
            exclude = ",".join(OPT_IN_ONLY)

            mappingTask = _make_task(
                GenerateFullMapping, 
                project_config=self.project_config, 
                org_config=self.org_config,
                path=dataset.mapping_file,
                include=sobjectListString,
                ignore=exclude
                )
            mappingTask()

            self.logger.info(f"Mapping saved to : {dataset.mapping_file}")
            if not self.preview:
                self._get_data_from_org(dataset)

    def _get_data_from_org(self, dataset: Dataset):
        self.logger.info(f"Extracting data to {dataset.path}")
        from tasks.data_ops.backup_data import ExtractBackup
        extractTask = _make_task(
            ExtractBackup,
            project_config=dataset.project_config,
            org_config=dataset.org_config,
            mapping=dataset.mapping_file,
            sql_path=dataset.path / "data.sql",
            )
        extractTask()

    def create_extract_mapping_file_from_declarations(
        self,
        decls: T.List[ExtractDeclaration], 
        schema: Schema, 
        opt_in_only: T.Sequence[str]
    ):
        """Create a mapping file sufficient for driving an extract process
        from an extract declarations file."""
        assert decls is not None
        
        from cumulusci.tasks.bulkdata.generate_mapping_utils.generate_mapping_from_declarations import (
            classify_and_filter_lookups
        )
        from tasks.data_ops.extract_dataset_utils.synthesize_extract_declarations import (
            flatten_declarations,
            )
        
        simplified_decls = flatten_declarations(decls, schema, opt_in_only)
        self.logger.info(f"Flattened Declarations: {simplified_decls}")
        simplified_decls = classify_and_filter_lookups(simplified_decls, schema)
        mappings = [self._mapping_decl_for_extract_decl(decl) for decl in simplified_decls]
        return dict(pair for pair in mappings if pair)

    def _mapping_decl_for_extract_decl(
        self,
        decl: SimplifiedExtractDeclarationWithLookups,
    ):
        """Make a CCI extract mapping step from a SimplifiedExtractDeclarationWithLookups"""
        lookups = {lookup: {"table": tables} for lookup, tables in decl.lookups.items()}
        mapping_dict: dict[str, T.Any] = {
            "sf_object": decl.sf_object,
        }
        if decl.where:
            mapping_dict["soql_filter"] = decl.where
        if decl.api:
            mapping_dict["api"] = decl.api.value
        mapping_dict["fields"] = decl.fields
        if lookups:
            mapping_dict["lookups"] = lookups

        return (decl.sf_object, mapping_dict)


class MappingStep(CumulusciMappingStep):

    def _check_field_permission(
        self, describe: Mapping, field: str, operation: DataOperationType
    ):
        perms = ("queryable",)
        # Fields don't have "queryable" permission.
        return field in describe and all(
            # To discuss: is this different than `describe[field].get(perm, True)`
            describe[field].get(perm) if perm in describe[field] else True
            for perm in perms
        )


class MappingSteps(CumulusciMappingSteps):
    __root__: Dict[str, MappingStep]


class ExtractBackup(ExtractData):

    task_options = extract_data_options

    def _init_mapping(self):
        """Load a YAML mapping file."""
        mapping_file_path = self.options["mapping"]
        if not mapping_file_path:
            raise TaskOptionsError("Mapping file path required")
        self.logger.info(f"Mapping file: {self.options['mapping']}")

        self.mapping = MappingSteps.parse_from_yaml(mapping_file_path)

        validate_and_inject_mapping(
            mapping=self.mapping,
            sf=self.sf,
            namespace=self.project_config.project__package__namespace,
            data_operation=DataOperationType.QUERY,
            inject_namespaces=self.options["inject_namespaces"],
            drop_missing=self.options["drop_missing_schema"],
            org_has_person_accounts_enabled=self.org_config.is_person_accounts_enabled,
        )

    # def _run_query(self, soql, mapping):
    #     """Run a query and write the results to a CSV file."""
    #     self.logger.info(f"Running query: {soql}")
    #     super()._run_query(soql, mapping)
